{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pycountry\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import lru_cache\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "import nest_asyncio\n",
    "from io import BytesIO\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from urllib.parse import quote, urlsplit, urlunsplit\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "9f507d6aa1885a35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загружаем снова датасет",
   "id": "b7b5abc4ec24701d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "file_path = 'links.tsv.gz'\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as file:\n",
    "    df = pd.read_csv(file, sep='\\t')"
   ],
   "id": "946670845fe74e2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выполним снова предобработку для сохранения датасета в формате картинок а не ссылок",
   "id": "afbf09ee005a2268"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# начнем с умного подхода: поищем совпадения в библиотеке pycountry\n",
    "@lru_cache(maxsize=None)\n",
    "def map_to_country(name):\n",
    "    try:\n",
    "        country = pycountry.countries.search_fuzzy(name)[0]\n",
    "        return country.name\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "df['country'] = df['nationality'].apply(map_to_country)\n",
    "manual_mapping = {\n",
    "    'united_kingdom': 'United Kingdom',\n",
    "    'kingdom_of_the_netherlands': 'Netherlands',\n",
    "    'united_states_of_america': 'United States',\n",
    "    'new_zealand': 'New Zealand',\n",
    "    'socialist_federal_republic_of_yugoslavia': 'Yugoslavia',\n",
    "    'czech_republic': 'Czech Republic',\n",
    "    'south_africa': 'South Africa',\n",
    "    \"people's_republic_of_china\": 'China',\n",
    "    'south_korea': 'Korea', ###\n",
    "    'soviet_union': 'Russian Federation',\n",
    "    'republic_of_china_(1912–1949)': 'China',\n",
    "    'turkey': 'Turkey',\n",
    "    'bosnia_and_herzegovina': 'Bosnia and Herzegovina',\n",
    "    'democratic_republic_of_the_congo': 'Democratic Republic of the Congo',\n",
    "    'western_sahara': 'Western Sahara',\n",
    "    'republic_of_macedonia': 'North Macedonia',\n",
    "    'yugoslavia': 'Yugoslavia',\n",
    "    'trinidad_and_tobago': 'Trinidad and Tobago',\n",
    "    'ivory_coast': 'Côte d\\'Ivoire',\n",
    "    'greenland':'Canada',\n",
    "    'puerto_rico': 'Puerto Rico',\n",
    "    'northern_ireland': 'United Kingdom',\n",
    "    'saudi_arabia': 'Saudi Arabia',\n",
    "    'republic_of_the_congo': 'Congo',\n",
    "    'palau':'Philippines', ###\n",
    "    'montserrat':'Cuba', ###\n",
    "    'north_korea': 'Korea', ###\n",
    "    'antigua_and_barbuda': 'Antigua and Barbuda',\n",
    "    'liechtenstein':'Israel', ###\n",
    "    'czechoslovakia': 'Czech Republic',\n",
    "    'sri_lanka': 'Sri Lanka',\n",
    "    'san_marino': 'San Marino',\n",
    "    'dominican_republic': 'Dominican Republic',\n",
    "    'state_of_palestine': 'Palestine, State of',\n",
    "    'burkina_faso': 'Burkina Faso',\n",
    "    'federated_states_of_micronesia': 'Micronesia, Federated States of',\n",
    "    'second_polish_republic': 'Poland',\n",
    "    'costa_rica': 'Costa Rica',\n",
    "    'british_raj': 'India',\n",
    "    'german_democratic_republic': 'Germany',\n",
    "    'united_arab_emirates': 'United Arab Emirates',\n",
    "    'faroe_islands': 'United kingdom', ###\n",
    "    'saint_kitts_and_nevis': 'Saint Kitts and Nevis',\n",
    "    'hong_kong': 'China', ###\n",
    "    \"people's_republic_of_poland\": 'Poland',\n",
    "    'serbia_and_montenegro': 'Serbia',\n",
    "    'nazi_germany': 'Germany',\n",
    "    'el_salvador': 'El Salvador',\n",
    "    'central_african_republic': 'Central African Republic',\n",
    "    'kingdom_of_yugoslavia': 'Yugoslavia',\n",
    "    'weimar_republic': 'Germany',\n",
    "    'kingdom_of_denmark': 'Denmark',\n",
    "    'saint_vincent_and_the_grenadines': 'Saint Vincent and the Grenadines',\n",
    "    'papua_new_guinea': 'Papua New Guinea',\n",
    "    'cape_verde': 'Cabo Verde',\n",
    "    'palestinian_national_authority': 'Palestine, State of',\n",
    "    'empire_of_japan': 'Japan',\n",
    "    'sierra_leone': 'Sierra Leone',\n",
    "    'east_timor': 'Indonesia', ###\n",
    "    'russian_soviet_federative_socialist_republic': 'Russian Federation',\n",
    "    'kingdom_of_serbs,_croatians_and_slovenes': 'Yugoslavia',\n",
    "    'tibet': 'China',\n",
    "    'mandatory_palestine': 'Palestine, State of',\n",
    "    'kingdom_of_italy': 'Italy',\n",
    "    'turkish_republic_of_northern_cyprus': 'Cyprus',\n",
    "    'kingdom_of_romania': 'Romania',\n",
    "    'guernsey':'United Kingdom', ###\n",
    "    'equatorial_guinea': 'Equatorial Guinea',\n",
    "    'transnistria': 'Romania',\n",
    "    'great_britain': 'United Kingdom',\n",
    "    'kingdom_of_iraq': 'Iraq',\n",
    "    'south_sudan': 'Sudan',\n",
    "    'ukrainian_soviet_socialist_republic': 'Ukraine',\n",
    "    'são_tomé_and_príncipe': 'São Tomé and Príncipe',\n",
    "    'artsakh': 'Azerbaijan',\n",
    "    'federal_republic_of_yugoslavia': 'Yugoslavia',\n",
    "    'armenian_soviet_socialist_republic': 'Armenia',\n",
    "    'kingdom_of_egypt': 'Egypt',\n",
    "    'francoist_spain': 'Spain',\n",
    "    'protectorate_of_bohemia_and_moravia': 'Czech Republic',\n",
    "    'west_germany': 'Germany',\n",
    "    'solomon_islands': 'Solomon Islands',\n",
    "    'saint_lucia': 'Saint Lucia',\n",
    "    'colonial_nigeria': 'Nigeria',\n",
    "    'kingdom_of_hungary': 'Hungary',\n",
    "    \"people's_republic_of_hungary\": 'Hungary',\n",
    "    'south_vietnam': 'Vietnam',\n",
    "    'isle_of_man': 'United Kingdom', ###\n",
    "    'manchukuo': 'China',\n",
    "    'laos': 'Laos',\n",
    "    'czechoslovak_socialist_republic': 'Czech Republic',\n",
    "    'british_hong_kong': 'China',\n",
    "    'slovak_state_(1939-1945)': 'Slovakia',\n",
    "    'kingdom_of_bulgaria': 'Bulgaria',\n",
    "    \"people's_republic_of_bulgaria\": 'Bulgaria',\n",
    "    'sultanate_of_zanzibar': 'Tanzania, United Republic of', ###\n",
    "    'dutch_east_indies': 'Indonesia',\n",
    "    'french_algeria': 'Algeria',\n",
    "    'marshall_islands': 'Marshall Islands',\n",
    "    'byelorussian_soviet_socialist_republic': 'Belarus',\n",
    "    'japanese_people': 'Japan',\n",
    "    'welsh_people': 'United Kingdom',\n",
    "    'british_people': 'United Kingdom',\n",
    "    'rhodesia': 'Zimbabwe',\n",
    "    'hungarian': 'Hungary',\n",
    "    'federation_of_rhodesia_and_nyasaland': 'Zimbabwe',\n",
    "    'socialist_republic_of_romania': 'Romania',\n",
    "    'kingdom_of_albania': 'Albania',\n",
    "    'iraqi_kurdistan': 'Iraq',\n",
    "    'union_of_south_africa': 'South Africa',\n",
    "    'indian_people': 'India',\n",
    "    'cook_islands': 'New Zealand', ###\n",
    "    'niue': 'New Zealand', ###\n",
    "    'georgian_soviet_socialist_republic': 'Georgia',\n",
    "    'southern_rhodesia': 'Zimbabwe',\n",
    "    'british_virgin_islands': 'United States',\n",
    "    'american_samoa': 'United States',\n",
    "    'danish': 'Denmark',\n",
    "    'kingdom_of_afghanistan': 'Afghanistan',\n",
    "    'first_republic_of_austria': 'Austria',\n",
    "    'british_empire': 'United Kingdom',\n",
    "    'kingdom_of_greece': 'Greece',\n",
    "    'belgian_congo': 'Democratic Republic of the Congo',\n",
    "    'macau': 'China',\n",
    "    \"people's_socialist_republic_of_albania\": 'Albania',\n",
    "    'yemen_arab_republic': 'Yemen',\n",
    "    'vatican_city': 'Italy',\n",
    "    'kenya_colony': 'Kenya',\n",
    "    'tibet_from_1912_to_1951': 'China',\n",
    "    'ruanda-urundi': 'Rwanda',\n",
    "    'german_empire': 'Germany',\n",
    "    'nepali': 'Nepal',\n",
    "    'united_kingdom_of_great_britain_and_ireland': 'United Kingdom',\n",
    "    'tuva_republic': 'Russian Federation',\n",
    "    'austrians': 'Austria',\n",
    "    'british_national_(overseas)': 'United Kingdom',\n",
    "    'filipino_people': 'Philippines',\n",
    "    'lithuanian_soviet_socialist_republic': 'Lithuania',\n",
    "    'country_of_the_kingdom_of_the_netherlands': 'Netherlands',\n",
    "    'netherlands_antilles': 'Netherlands',\n",
    "    'republic_of_upper_volta': 'Burkina Faso',\n",
    "    'first_portuguese_republic': 'Portugal',\n",
    "    \"romanian_people's_republic\": 'Romania',\n",
    "    \"mongolian_people's_republic\": 'Mongolia',\n",
    "    'democratic_republic_of_georgia': 'Georgia',\n",
    "    'azerbaijani': 'Azerbaijan',\n",
    "    'bangladeshis': 'Bangladesh',\n",
    "    'bulgarian': 'Bulgaria',\n",
    "    'italians': 'Italy',\n",
    "    'american_occupation_zone': 'Germany',\n",
    "    'republic_of_cuba_(1902–59)': 'Cuba',\n",
    "    'south_yemen': 'Yemen',\n",
    "    'irish_republic': 'Ireland',\n",
    "    'british_somaliland': 'Somalia',\n",
    "    'chinese_taipei': 'China',\n",
    "    'bosniaks': 'Bosnia and Herzegovina',\n",
    "    'tibetan_people': 'China',\n",
    "    'kingdom_of_mysore': 'India',\n",
    "    'beiyang_government': 'China',\n",
    "    'afrika': 'South Africa',\n",
    "    'americans': 'United States',\n",
    "    'chileans': 'Chile',\n",
    "    'sint_maarten': 'Netherlands',\n",
    "    'hungarians': 'Hungary',\n",
    "    'norwegian': 'Norway',\n",
    "    'irish': 'Ireland',\n",
    "    'czechoslovak_republic': 'Czech Republic',\n",
    "    'mexicana': 'Mexico',\n",
    "    'cayman_islands': 'Cuba',\n",
    "    'são_paulo': 'Brazil',\n",
    "    'québec-comté': 'Canada',\n",
    "    'israelis': 'Israel',\n",
    "    'range_of_andia': 'Spain',\n",
    "    'anguilla':'Cuba',\n",
    "    'marítimo': 'Portugal',\n",
    "    'chilena': 'Chile',\n",
    "    'canadian_french': 'Canada',\n",
    "    'egyptians': 'Egypt',\n",
    "    'francia': 'France',\n",
    "    'ukrainians': 'Ukraine',\n",
    "    'dominicana': 'Dominican Republic',\n",
    "    'kurdistan': 'Turkey',\n",
    "    'germans': 'Germany',\n",
    "    'the_republic_of_abkhazia': 'Georgia', #### упс...\n",
    "    'united_federation_of_planets': 'United States', # легенда\n",
    "    'katun': 'Russian Federation',\n",
    "    'siciliana': 'Italy',\n",
    "    'soviètic': 'Russian Federation',\n",
    "    'first_hungarian_republic': 'Hungary',\n",
    "    'staffanstorp_municipality': 'Sweden',\n",
    "    'nuu-chah-nulth': 'Canada',\n",
    "    'croacia': 'Croatia',\n",
    "    'liberland': 'Czech Republic',\n",
    "    'spain_under_the_restoration': 'Spain',\n",
    "    'venezolano.': 'Venezuela, Bolivarian Republic of',\n",
    "    'estado_novo': 'Portugal',\n",
    "    'ivanteyevskaya_street': 'Russian Federation',\n",
    "    'kuwait_city': 'Kuwait',\n",
    "    'florence': 'Italy',\n",
    "    'monterrey': 'Mexico',\n",
    "    'moldova':'Romania', ###\n",
    "    'colombiana': 'Colombia',\n",
    "    'ss_france': 'France',\n",
    "    'francais_objective_specifique': 'France',\n",
    "    'mexico_city': 'Mexico',\n",
    "    'morocco_pavilion': 'Morocco',\n",
    "    'brazil–uruguay_relations': 'Brazil',\n",
    "    'ecuador_national_football_team': 'Ecuador',\n",
    "    'langnau_am_albis': 'Switzerland',\n",
    "    \"federal_people's_republic_of_yugoslavia\": 'Yugoslavia',\n",
    "    'third_czechoslovak_republic': 'Czech Republic',\n",
    "    'plastin': 'Romania',\n",
    "    'nazareth': 'Israel',\n",
    "    'korea':'Korea', ###\n",
    "    'suisse_romande': 'Switzerland',\n",
    "    'republika_srpska': 'Bosnia and Herzegovina',\n",
    "    'san_luis_potosí': 'Mexico',\n",
    "    'república_de_síria': 'Syrian Arab Republic',\n",
    "    'tamil_eelam': 'Sri Lanka',\n",
    "    'sockel_fm2+': 'Spain', # немного непонятно при чем тут розетка...\n",
    "    'canadian_nationality_law': 'Canada',\n",
    "    'bicycle_kick': 'Chile',\n",
    "    'santo_domingo': 'Dominican Republic',\n",
    "    'québécois': 'Canada',\n",
    "}\n",
    "df['country'] = df['nationality'].map(manual_mapping).combine_first(df['country'])\n",
    "df.loc[df[\"label\"] == \"Eliana Rubashkyn\", \"country\"] = \"Colombia\"\n",
    "df.loc[df[\"label\"] == \"Glen L Roberts\", \"country\"] = \"United States\"\n",
    "df.loc[df[\"label\"] == \"Denis Pécic\", \"country\"] = \"France\"\n",
    "df = df.dropna(subset=['country'])"
   ],
   "id": "2beedc117c8802bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# словарь для группировки редких стран\n",
    "country_groups = {\n",
    "    'Caribbean': [\n",
    "        'Antigua and Barbuda', 'Bahamas', 'Barbados', \n",
    "        'Grenada', 'Saint Kitts and Nevis', 'Saint Lucia',\n",
    "        'Saint Vincent and the Grenadines', 'Aruba', 'Bermuda',\n",
    "        'Belize', 'Guyana'\n",
    "    ],\n",
    "    'Pacific Islands': [\n",
    "        'Kiribati', 'Marshall Islands', 'Micronesia, Federated States of',\n",
    "        'Nauru', 'Guam', 'Solomon Islands', 'Tuvalu', 'Vanuatu',\n",
    "        'Papua New Guinea', 'Samoa'\n",
    "    ],\n",
    "    'African Small States': [\n",
    "        'Botswana', 'Burundi', 'Cabo Verde', 'Comoros',\n",
    "        'Djibouti', 'Equatorial Guinea', 'Eswatini', 'Gabon', 'Gambia', 'Eritrea',\n",
    "        'Guinea-Bissau', 'Lesotho', 'Malawi', 'Mauritania', 'Mauritius', 'Mozambique',\n",
    "        'São Tomé and Príncipe', 'Seychelles', 'Togo', 'Madagascar',\n",
    "        'Central African Republic', 'Chad', 'Sierra Leone', 'Liberia'                               \n",
    "    ],\n",
    "    'Central Asia': [\n",
    "        'Kyrgyzstan', 'Tajikistan', 'Turkmenistan', 'Uzbekistan'\n",
    "    ],\n",
    "    'Middle East Small States': [\n",
    "        'Brunei Darussalam', 'Oman', 'Qatar', 'Western Sahara', 'Yemen'\n",
    "    ],\n",
    "    'Other Europe': [\n",
    "        'Gibraltar', 'Monaco', 'San Marino'\n",
    "    ],\n",
    "    'Other Asia': [\n",
    "        'Bhutan', 'Maldives', 'Laos', 'Vietnam'\n",
    "    ]\n",
    "}\n",
    "\n",
    "country_counts = df['country'].value_counts()\n",
    "keep_individual = country_counts[country_counts > 49].index.tolist() #названия стран где 50 и больше строк не меняем\n",
    "def group_country(country):\n",
    "    if country in keep_individual:\n",
    "        return country\n",
    "    for group, countries in country_groups.items():\n",
    "        if country in countries:\n",
    "            return group\n",
    "    return 'Other'  #на всякий случай\n",
    "\n",
    "df = df.copy()\n",
    "df.loc[:, 'country'] = df['country'].apply(group_country)"
   ],
   "id": "5f7f711428b1747b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Подготавливаем почву для загрузки картинок по ссылкам\n",
    "\n",
    "Применим умный подход, так как изображений >300к, и будем их загружать асинхронно (многопоточно) по батчам датасета, для уменьшения количества ошибок из-за перегрузки сервера\n",
    "\n",
    "При этом будем сразу сохранять полученные валидные ссылки, чтобы знать какие строчки не валидны а какие нет"
   ],
   "id": "16244d9bbc7eac26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_root = \"dataset\"\n",
    "SEM_LIMIT = 40\n",
    "\n",
    "def safe_url(url):\n",
    "    try:\n",
    "        parts = urlsplit(url)\n",
    "        safe_path = quote(parts.path)\n",
    "        return urlunsplit((parts.scheme, parts.netloc, safe_path, parts.query, parts.fragment))\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "async def is_url_accessible(session, url, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            url = safe_url(url)\n",
    "            async with session.get(url, timeout=5) as resp:\n",
    "                return resp.status == 200\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "async def download_image(session, row, index, semaphore, failed_rows):\n",
    "    url = safe_url(row['image'])\n",
    "    class_name = str(row['country']).strip().lower().replace(\" \", \"_\")\n",
    "    class_dir = os.path.join(dataset_root, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "    async with semaphore:\n",
    "        await asyncio.sleep(random.uniform(0.1, 0.3))\n",
    "\n",
    "        try:\n",
    "            async with session.get(url, timeout=5) as resp:\n",
    "                if resp.status == 200:\n",
    "                    content = await resp.read()\n",
    "                    try:\n",
    "                        image = Image.open(BytesIO(content)).convert('RGB')\n",
    "                        image.save(os.path.join(class_dir, f\"{index}.jpg\"))\n",
    "                    except UnidentifiedImageError:\n",
    "                        failed_rows.append(row)\n",
    "                        print(f\"[{index}] Нераспознанный формат изображения\")\n",
    "                else:\n",
    "                    failed_rows.append(row)\n",
    "                    print(f\"[{index}] HTTP статус: {resp.status}\")\n",
    "        except Exception as e:\n",
    "            failed_rows.append(row)\n",
    "            print(f\"[{index}] Ошибка скачивания: {e}\")\n",
    "\n",
    "async def process_all(df):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Referer': 'https://google.com'\n",
    "    }\n",
    "\n",
    "    semaphore = asyncio.Semaphore(SEM_LIMIT)\n",
    "    failed_rows = []\n",
    "\n",
    "    async with aiohttp.ClientSession(headers=headers) as session:\n",
    "        tasks_check = [\n",
    "            is_url_accessible(session, url, semaphore) if pd.notna(url) else False\n",
    "            for url in df['image']\n",
    "        ]\n",
    "        valid_mask = await tqdm_asyncio.gather(*tasks_check, position=0, desc=\"Проверка URL\")\n",
    "        valid_mask = pd.Series(valid_mask, index=df.index)\n",
    "\n",
    "        df_valid = df[valid_mask].reset_index(drop=True)\n",
    "        df_failed_check = df[~valid_mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        tasks_download = [\n",
    "            download_image(session, row, row[\"id\"], semaphore, failed_rows)\n",
    "            for _, row in df_valid.iterrows()\n",
    "        ]\n",
    "        await tqdm_asyncio.gather(*tasks_download, position=0, desc=\"Загрузка изображений\")\n",
    "\n",
    "    df_failed_download = pd.DataFrame(failed_rows)\n",
    "    df_failed_total = pd.concat([df_failed_check, df_failed_download], ignore_index=True)\n",
    "    return df_valid, df_failed_total\n",
    "\n",
    "async def process_all_in_batches(df, batch_size=10000, sleep_between_batches=30):\n",
    "    total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    all_valid, all_failed = [], []\n",
    "\n",
    "    for i in range(total_batches):\n",
    "        start, end = i * batch_size, min((i + 1) * batch_size, len(df))\n",
    "        df_batch = df.iloc[start:end]\n",
    "        print(f\"\\n🔹 Обработка батча {i+1}/{total_batches} ({start}–{end})\")\n",
    "\n",
    "        df_valid, df_failed = await process_all(df_batch)\n",
    "        all_valid.append(df_valid)\n",
    "        all_failed.append(df_failed)\n",
    "\n",
    "        print(f\"✅ Батч {i+1} завершён, пауза {sleep_between_batches} сек...\\n\")\n",
    "        await asyncio.sleep(sleep_between_batches)\n",
    "\n",
    "    df_valid_final = pd.concat(all_valid, ignore_index=True)\n",
    "    df_failed_final = pd.concat(all_failed, ignore_index=True)\n",
    "    return df_valid_final, df_failed_final"
   ],
   "id": "53e2ac2ef8aab3e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nest_asyncio.apply()",
   "id": "ca7ba0d62b888fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T23:34:38.218357Z",
     "start_time": "2025-05-14T23:34:38.214261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_valid_1, df_fail_1 = await process_all_in_batches(df[:100000], batch_size=1000, sleep_between_batches=10)\n",
    "# df_valid_1.to_csv(\"df_valid_1.csv\", index=True)\n",
    "# df_fail_1.to_csv(\"df_fail_1.csv\", index=True)"
   ],
   "id": "15dc6861ea0d5582",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T23:34:20.718303Z",
     "start_time": "2025-05-14T23:34:20.713319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# df_valid_2, df_fail_2 = await process_all_in_batches(df[100000:200000], batch_size=1000, sleep_between_batches=10)\n",
    "# df_valid_2.to_csv(\"df_valid_2.csv\", index=True)\n",
    "# df_fail_2.to_csv(\"df_fail_2.csv\", index=True)"
   ],
   "id": "6c023e32c686cba9",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df_valid_3, df_fail_3 = await process_all_in_batches(df[200000:], batch_size=1000, sleep_between_batches=10)\n",
    "# df_valid_3.to_csv(\"df_valid_3.csv\", index=True)\n",
    "# df_fail_3.to_csv(\"df_fail_3.csv\", index=True)"
   ],
   "id": "4b69c343d5d1c1d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Сохраним полученный результат в `.csv` файл и затем объединим полученные датафрейм с последующим его сохранением",
   "id": "1960d72dbdacc5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_valid_1 = pd.read_csv(\"df_valid_1.csv\")\n",
    "df_valid_2 = pd.read_csv(\"df_valid_2.csv\")\n",
    "df_valid_3 = pd.read_csv(\"df_valid_3.csv\")\n",
    "df_fail_1 = pd.read_csv(\"df_fail_1.csv\")\n",
    "df_fail_2 = pd.read_csv(\"df_fail_2.csv\")\n",
    "df_fail_3 = pd.read_csv(\"df_fail_3.csv\")"
   ],
   "id": "bed2d4d98925c701"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_valid = pd.concat([df_valid_1, df_valid_2, df_valid_3], ignore_index=True)\n",
    "df_failed = pd.concat([df_fail_1, df_fail_2, df_fail_3], ignore_index=True)"
   ],
   "id": "aa842025f3c478d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В теории тут должно быть создание архива для выгрузки его в яндекс датасфера\n",
    "\n",
    "P.S. эту ячейку можно не делать потому что далее создается отдельная директория с разделением которую опять будем архивировать"
   ],
   "id": "af8d9ad052a30d6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# shutil.make_archive(\"dataset\", 'zip', \"dataset\")",
   "id": "158c58018d8b1ade"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Разделяем датасет тренировочные, валидационные и тестовые данные с сохранением балансов классов",
   "id": "c53815bc4b222d8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# dataset = ImageFolder(root=\"dataset\")\n",
    "#\n",
    "# file_paths = [sample[0] for sample in dataset.samples]\n",
    "# labels = [sample[1] for sample in dataset.samples]\n",
    "#\n",
    "#\n",
    "# # Сначала разделяем на train+val (80%) и test (20%)\n",
    "# train_val_files, test_files, train_val_labels, test_labels = train_test_split(\n",
    "#     file_paths,\n",
    "#     labels,\n",
    "#     test_size=0.2,\n",
    "#     stratify=labels,\n",
    "#     random_state=30\n",
    "# )\n",
    "# # Разделяем train_val на train и val\n",
    "# train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "#     train_val_files,\n",
    "#     train_val_labels,\n",
    "#     test_size=0.2,\n",
    "#     stratify=train_val_labels,\n",
    "#     random_state=30\n",
    "# )\n",
    "#\n",
    "# # Загружаем полный датасет с преобразованиями\n",
    "# full_dataset = ImageFolder(root=\"dataset\", transform=None)\n",
    "#\n",
    "# # Создаем словарь для индексов (чтобы сопоставить пути с индексами в full_dataset)\n",
    "# file_to_index = {os.path.normpath(path): idx for idx, (path, _) in enumerate(full_dataset.samples)}\n",
    "#\n",
    "# # Получаем индексы для train, val, test\n",
    "# train_indices = [file_to_index[os.path.normpath(path)] for path in train_files]\n",
    "# val_indices = [file_to_index[os.path.normpath(path)] for path in val_files]\n",
    "# test_indices = [file_to_index[os.path.normpath(path)] for path in test_files]\n",
    "#\n",
    "#\n",
    "# train_dataset = Subset(full_dataset, train_indices)\n",
    "# val_dataset = Subset(full_dataset, val_indices)\n",
    "# test_dataset = Subset(full_dataset, test_indices)\n",
    "#\n",
    "# # Создаем поддиректории\n",
    "# os.makedirs(\"split_dataset/train\", exist_ok=True)\n",
    "# os.makedirs(\"split_dataset/val\", exist_ok=True)\n",
    "# os.makedirs(\"split_dataset/test\", exist_ok=True)\n",
    "#\n",
    "# def copy_files(files, target_dir):\n",
    "#     for file in files:\n",
    "#         class_name = os.path.basename(os.path.dirname(file))\n",
    "#         dest_dir = os.path.join(target_dir, class_name)\n",
    "#         os.makedirs(dest_dir, exist_ok=True)\n",
    "#         shutil.copy(file, dest_dir)\n",
    "#\n",
    "# copy_files(train_files, \"split_dataset/train\")\n",
    "# copy_files(val_files, \"split_dataset/val\")\n",
    "# copy_files(test_files, \"split_dataset/test\")"
   ],
   "id": "f63d68286d5cfe91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем распределение классов",
   "id": "77588d4a7019f0b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_dataset = ImageFolder(\"split_dataset/train\", transform=None)\n",
    "# val_dataset = ImageFolder(\"split_dataset/val\", transform=None)\n",
    "# test_dataset = ImageFolder(\"split_dataset/test\", transform=None)\n",
    "#\n",
    "# def print_class_distribution(dataset, name):\n",
    "#     if isinstance(dataset, Subset):\n",
    "#         labels = [dataset.dataset.targets[i] for i in dataset.indices]\n",
    "#     else:\n",
    "#         labels = dataset.targets\n",
    "#     unique, counts = np.unique(labels, return_counts=True)\n",
    "#     print(f\"{name} distribution:\")\n",
    "#     for cls, count in zip(unique, counts):\n",
    "#         print(f\"Class {cls}: {count} samples ({count / len(labels):.2%})\")\n",
    "#\n",
    "# print_class_distribution(train_dataset, \"Train\")\n",
    "# print_class_distribution(val_dataset, \"Validation\")\n",
    "# print_class_distribution(test_dataset, \"Test\")"
   ],
   "id": "6a746ac6d31fabe0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Опять-таки архивируем разделенный датасет для последующей загрузки в яндекс датасфера",
   "id": "c9a1b9dce97b42de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# shutil.make_archive(\"split_dataset\", 'zip', \"split_dataset\")",
   "id": "85221dcaa7122931"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
